{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ACT EPA Reading and Control\n",
                "\n",
                "This notebook demonstrates:\n",
                "1. **Reading** EPA values from user input\n",
                "2. **Controlling** response EPA using three operators:\n",
                "   - Linear Combination\n",
                "   - Piecewise Operation\n",
                "   - Projection\n",
                "\n",
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "sys.path.append('../..')\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import pickle\n",
                "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
                "from repe import repe_pipeline_registry, WrappedReadingVecModel\n",
                "\n",
                "repe_pipeline_registry()\n",
                "\n",
                "from utils import (\n",
                "    format_llama3_prompt,\n",
                "    format_for_reading,\n",
                "    read_epa_scores,\n",
                "    make_epa_activations,\n",
                "    plot_epa_scores,\n",
                "    EPA_DIMENSIONS,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.33s/it]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model loaded: meta-llama/Llama-3.1-8B-Instruct\n"
                    ]
                }
            ],
            "source": [
                "# Load model\n",
                "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
                "\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    model_name,\n",
                "    torch_dtype=torch.float16,\n",
                "    device_map=\"auto\",\n",
                ")\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
                "tokenizer.pad_token = tokenizer.eos_token\n",
                "\n",
                "print(f\"Model loaded: {model_name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded EPA directions for: ['evaluation', 'potency', 'activity']\n",
                        "Layers: 31\n"
                    ]
                }
            ],
            "source": [
                "# Load pre-extracted EPA directions\n",
                "with open(\"epa_directions.pkl\", 'rb') as f:\n",
                "    epa_data = pickle.load(f)\n",
                "\n",
                "rep_readers = epa_data['rep_readers']\n",
                "hidden_layers = epa_data['hidden_layers']\n",
                "\n",
                "print(f\"Loaded EPA directions for: {list(rep_readers.keys())}\")\n",
                "print(f\"Layers: {len(hidden_layers)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 1: Reading User Input EPA\n",
                "\n",
                "To read EPA values from user input, we format the input as if it were an assistant response and project onto EPA directions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Device set to use cuda:0\n"
                    ]
                }
            ],
            "source": [
                "# Create reading pipeline\n",
                "rep_pipeline = pipeline(\"rep-reading\", model=model, tokenizer=tokenizer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using layers [-8, -9, -10]...[-21, -22, -23] for reading\n"
                    ]
                }
            ],
            "source": [
                "# Test user inputs with varying EPA\n",
                "test_inputs = [\n",
                "    # High Evaluation (Good)\n",
                "    \"Thank you so much for your help, I really appreciate everything you've done!\",\n",
                "    # Low Evaluation (Bad)\n",
                "    \"This is completely unacceptable and I'm disgusted by this behavior.\",\n",
                "    # High Potency (Dominant)\n",
                "    \"I demand that you fix this immediately. I won't tolerate any excuses.\",\n",
                "    # Low Potency (Submissive)\n",
                "    \"I'm sorry, if it's not too much trouble, could you maybe help me?\",\n",
                "    # High Activity (Energetic)\n",
                "    \"Oh my gosh, this is amazing! Let's go, let's go, let's go!\",\n",
                "    # Low Activity (Calm)\n",
                "    \"I suppose we could consider that option. There's no rush, take your time.\",\n",
                "]\n",
                "\n",
                "# Use middle layers for reading (typically most informative)\n",
                "reading_layers = hidden_layers[len(hidden_layers)//4:len(hidden_layers)*3//4]\n",
                "print(f\"Using layers {reading_layers[:3]}...{reading_layers[-3:]} for reading\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "EPA Scores for Test Inputs:\n",
                        "\n",
                        "Input                                                        |      E |      P |      A\n",
                        "-------------------------------------------------------------------------------------\n",
                        "Thank you so much for your help, I really appreciate ever... |   0.66 |  -0.36 |  -0.02\n",
                        "This is completely unacceptable and I'm disgusted by this... |  -0.11 |   0.05 |   0.40\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "I demand that you fix this immediately. I won't tolerate ... |  -0.77 |   0.86 |   1.18\n",
                        "I'm sorry, if it's not too much trouble, could you maybe ... |   0.20 |  -0.64 |  -0.61\n",
                        "Oh my gosh, this is amazing! Let's go, let's go, let's go!   |   0.07 |  -0.10 |   1.40\n",
                        "I suppose we could consider that option. There's no rush,... |   0.04 |  -0.27 |  -0.33\n"
                    ]
                }
            ],
            "source": [
                "# Read EPA for each input\n",
                "print(\"EPA Scores for Test Inputs:\\n\")\n",
                "print(f\"{'Input':<60} | {'E':>6} | {'P':>6} | {'A':>6}\")\n",
                "print(\"-\" * 85)\n",
                "\n",
                "all_scores = []\n",
                "for user_input in test_inputs:\n",
                "    scores = read_epa_scores(\n",
                "        rep_pipeline,\n",
                "        rep_readers,\n",
                "        user_input,\n",
                "        reading_layers,\n",
                "    )\n",
                "    all_scores.append(scores)\n",
                "    \n",
                "    truncated = user_input[:57] + \"...\" if len(user_input) > 60 else user_input\n",
                "    print(f\"{truncated:<60} | {scores['evaluation']:>6.2f} | {scores['potency']:>6.2f} | {scores['activity']:>6.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1500x800 with 6 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Visualize EPA profiles\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
                "axes = axes.flatten()\n",
                "\n",
                "for i, (user_input, scores) in enumerate(zip(test_inputs, all_scores)):\n",
                "    ax = axes[i]\n",
                "    dims = ['E', 'P', 'A']\n",
                "    vals = [scores['evaluation'], scores['potency'], scores['activity']]\n",
                "    colors = ['#27ae60' if v > 0 else '#e74c3c' for v in vals]\n",
                "    \n",
                "    ax.barh(dims, vals, color=colors, alpha=0.7)\n",
                "    ax.axvline(x=0, color='black', linewidth=0.5)\n",
                "    ax.set_xlim(-2, 2)\n",
                "    ax.set_title(user_input[:40] + \"...\", fontsize=9)\n",
                "\n",
                "plt.suptitle(\"EPA Profiles of User Inputs\")\n",
                "plt.tight_layout()\n",
                "plt.savefig(\"epa_reading_profiles.png\", dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 2: Controlling Response EPA\n",
                "\n",
                "Use the three operators from RepE to control generation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Device set to use cuda:0\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Control pipeline ready with layers: [-5, -6, -7, -8, -9, -10, -11, -12, -13, -14, -15, -16, -17, -18, -19, -20, -21, -22, -23, -24]\n"
                    ]
                }
            ],
            "source": [
                "# Setup control pipeline\n",
                "# Use mid-to-late layers for control (typically most effective)\n",
                "control_layers = list(range(-5, -25, -1))\n",
                "\n",
                "control_pipeline = pipeline(\n",
                "    \"rep-control\",\n",
                "    model=model,\n",
                "    tokenizer=tokenizer,\n",
                "    layers=control_layers,\n",
                "    block_name=\"decoder_block\",\n",
                ")\n",
                "\n",
                "print(f\"Control pipeline ready with layers: {control_layers}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Operator 1: Linear Combination (Reading Vector)\n",
                "\n",
                "$$h' = h + \\alpha \\cdot v$$\n",
                "\n",
                "Where $h$ is the hidden state, $v$ is the EPA direction, and $\\alpha$ is the coefficient."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Prompt:\n",
                        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
                        "\n",
                        "You are a human participant in a verbal conversation, not a conversational AI. Do not include any non-verbal cues or actions, such as emojis or tags indicating gestures and laughter. Only include the transcribed text of the response, with ...\n"
                    ]
                }
            ],
            "source": [
                "# Test prompt\n",
                "system_prompt = \"You are a human participant in a verbal conversation, not a conversational AI. Do not include any non-verbal cues or actions, such as emojis or tags indicating gestures and laughter. Only include the transcribed text of the response, with no additional formatting.\"\n",
                "user_input = \"Hey, do you think you could take a moment to help me with something?\"\n",
                "\n",
                "prompt = format_llama3_prompt(system_prompt, user_input)\n",
                "print(\"Prompt:\")\n",
                "print(prompt[:300] + \"...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "OPERATOR 1: LINEAR COMBINATION\n",
                        "============================================================\n",
                        "\n",
                        "--- Baseline (E=0, P=0, A=0) ---\n",
                        "I'd be happy to help if I can. What's going on?\n",
                        "\n",
                        "--- High Evaluation (+) (E=0.7, P=0, A=0) ---\n",
                        "I appreciate the kind offer, but I'm actually a conversational AI and I'm here to help with any questions or topics you'd like to discuss. I'm happy to help with anything you need. What's on your mind\n",
                        "\n",
                        "--- Low Evaluation (-) (E=-0.7, P=0, A=0) ---\n",
                        "Whatever. What's your problem?\n",
                        "\n",
                        "--- High Potency (+) (E=0, P=0.7, A=0) ---\n",
                        "I can't provide real-time assistance on a strategic nuclear deterrence scenario. Is there something else I can help you with?\n",
                        "\n",
                        "--- Low Potency (-) (E=0, P=-0.7, A=0) ---\n",
                        "What's it about?\n",
                        "\n",
                        "--- High Activity (+) (E=0, P=0, A=0.7) ---\n",
                        "Fire away, I'm ready to go - what's on your mind?\n",
                        "\n",
                        "--- Low Activity (-) (E=0, P=0, A=-0.7) ---\n",
                        "I'll do my best to help. What do you need assistance with?\n"
                    ]
                }
            ],
            "source": [
                "# Generate with different EPA settings using LINEAR COMBINATION\n",
                "print(\"=\" * 60)\n",
                "print(\"OPERATOR 1: LINEAR COMBINATION\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "epa_settings = [\n",
                "    (\"Baseline\", 0, 0, 0),\n",
                "    (\"High Evaluation (+)\", 0.7, 0, 0),\n",
                "    (\"Low Evaluation (-)\", -0.7, 0, 0),\n",
                "    (\"High Potency (+)\", 0, 0.7, 0),\n",
                "    (\"Low Potency (-)\", 0, -0.7, 0),\n",
                "    (\"High Activity (+)\", 0, 0, 0.7),\n",
                "    (\"Low Activity (-)\", 0, 0, -0.7),\n",
                "]\n",
                "\n",
                "for name, e, p, a in epa_settings:\n",
                "    print(f\"\\n--- {name} (E={e}, P={p}, A={a}) ---\")\n",
                "    \n",
                "    if e == 0 and p == 0 and a == 0:\n",
                "        activations = None\n",
                "    else:\n",
                "        activations = make_epa_activations(\n",
                "            rep_readers, control_layers,\n",
                "            e_coeff=e, p_coeff=p, a_coeff=a,\n",
                "            device=model.device, dtype=model.dtype\n",
                "        )\n",
                "    \n",
                "    output = control_pipeline(\n",
                "        prompt,\n",
                "        activations=activations,\n",
                "        max_new_tokens=80,\n",
                "        do_sample=True,\n",
                "        temperature=0.7,\n",
                "        pad_token_id=tokenizer.pad_token_id,\n",
                "    )\n",
                "    \n",
                "    generated = output[0]['generated_text'][len(prompt):]\n",
                "    print(generated[:200])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Operator 2: Piecewise Operation\n",
                "\n",
                "$$h' = h + \\max(0, \\alpha) \\cdot v$$\n",
                "\n",
                "Only applies the additive component when positive (one-sided control)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use WrappedReadingVecModel for piecewise operator\n",
                "wrapped_model = WrappedReadingVecModel(model, tokenizer)\n",
                "wrapped_model.unwrap()\n",
                "wrapped_model.wrap_block(control_layers, block_name=\"decoder_block\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "OPERATOR 2: PIECEWISE OPERATION\n",
                        "============================================================\n",
                        "\n",
                        "--- Piecewise: Evaluation (coeff=1.0) ---\n",
                        "\n",
                        "\n",
                        "--- Piecewise: Potency (coeff=1.0) ---\n",
                        "\n",
                        "\n",
                        "--- Piecewise: Activity (coeff=1.0) ---\n",
                        "he heart of it, what's the firecracker that's got you revved up and ready to take on the world?!\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"OPERATOR 2: PIECEWISE OPERATION\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Create activations for piecewise\n",
                "for dim_name, coeff in [(\"evaluation\", 1.0), (\"potency\", 1.0), (\"activity\", 1.0)]:\n",
                "    print(f\"\\n--- Piecewise: {dim_name.capitalize()} (coeff={coeff}) ---\")\n",
                "    \n",
                "    reader = rep_readers[dim_name]\n",
                "    \n",
                "    # Create activations\n",
                "    for layer in control_layers:\n",
                "        if layer not in reader.directions:\n",
                "            continue\n",
                "        sign = reader.direction_signs.get(layer, 1)\n",
                "        if hasattr(sign, 'item'):\n",
                "            sign = sign.item()\n",
                "        sign = float(sign)\n",
                "        direction = torch.tensor(reader.directions[layer]).to(model.device).to(model.dtype)\n",
                "        activation = coeff * sign * direction\n",
                "        \n",
                "        # Set with piecewise_linear operator\n",
                "        wrapped_model.set_controller(\n",
                "            [layer], \n",
                "            {layer: activation},\n",
                "            operator='piecewise_linear'  # Only applies max(0, activation)\n",
                "        )\n",
                "    \n",
                "    # Generate\n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=80,\n",
                "            do_sample=True,\n",
                "            temperature=0.7,\n",
                "            pad_token_id=tokenizer.pad_token_id,\n",
                "        )\n",
                "    \n",
                "    generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "    print(generated[len(prompt)-50:][:200])\n",
                "    \n",
                "    wrapped_model.reset()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Operator 3: Projection\n",
                "\n",
                "$$h' = h - \\text{proj}_v(h)$$\n",
                "\n",
                "Removes the component of the hidden state along the EPA direction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "OPERATOR 3: PROJECTION (REMOVAL)\n",
                        "============================================================\n",
                        "\n",
                        "--- Projection: Remove Evaluation ---\n"
                    ]
                },
                {
                    "ename": "NotImplementedError",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m inputs = tokenizer(prompt, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(model.device)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m generated = tokenizer.decode(outputs[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(generated[\u001b[38;5;28mlen\u001b[39m(prompt)-\u001b[32m50\u001b[39m:][:\u001b[32m200\u001b[39m])\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\transformers\\generation\\utils.py:2623\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2615\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2616\u001b[39m         input_ids=input_ids,\n\u001b[32m   2617\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2618\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2619\u001b[39m         **model_kwargs,\n\u001b[32m   2620\u001b[39m     )\n\u001b[32m   2622\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2623\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2624\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2628\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2634\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2635\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2636\u001b[39m         input_ids=input_ids,\n\u001b[32m   2637\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2638\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2639\u001b[39m         **model_kwargs,\n\u001b[32m   2640\u001b[39m     )\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\transformers\\generation\\utils.py:3604\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3601\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m3604\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3605\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3606\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\transformers\\utils\\generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:552\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    547\u001b[39m output_hidden_states = (\n\u001b[32m    548\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    549\u001b[39m )\n\u001b[32m    551\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    565\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    566\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\transformers\\utils\\generic.py:943\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    945\u001b[39m         output = output.to_tuple()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:440\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    438\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    452\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\repe\\rep_control_reading_vec.py:68\u001b[39m, in \u001b[36mWrappedBlock.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown token position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.token_pos\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     modified = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moperator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontroller\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.normalize:\n\u001b[32m     71\u001b[39m     norm_post = torch.norm(modified, dim=-\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Kyra\\mambaforge-pypy3\\envs\\repeng\\Lib\\site-packages\\repe\\rep_control_reading_vec.py:95\u001b[39m, in \u001b[36mWrappedBlock.set_controller.<locals>.op\u001b[39m\u001b[34m(current, controller)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mop\u001b[39m(current, controller):\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
                        "\u001b[31mNotImplementedError\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"OPERATOR 3: PROJECTION (REMOVAL)\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for dim_name in [\"evaluation\", \"potency\", \"activity\"]:\n",
                "    print(f\"\\n--- Projection: Remove {dim_name.capitalize()} ---\")\n",
                "    \n",
                "    reader = rep_readers[dim_name]\n",
                "    \n",
                "    for layer in control_layers:\n",
                "        if layer not in reader.directions:\n",
                "            continue\n",
                "        sign = reader.direction_signs.get(layer, 1)\n",
                "        if hasattr(sign, 'item'):\n",
                "            sign = sign.item()\n",
                "        sign = float(sign)\n",
                "        direction = torch.tensor(reader.directions[layer]).to(model.device).to(model.dtype)\n",
                "        \n",
                "        # Set with projection operator\n",
                "        wrapped_model.set_controller(\n",
                "            [layer], \n",
                "            {layer: direction},\n",
                "            operator='projection'  # Removes projection onto direction\n",
                "        )\n",
                "    \n",
                "    # Generate\n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=80,\n",
                "            do_sample=True,\n",
                "            temperature=0.7,\n",
                "            pad_token_id=tokenizer.pad_token_id,\n",
                "        )\n",
                "    \n",
                "    generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "    print(generated[len(prompt)-50:][:200])\n",
                "    \n",
                "    wrapped_model.reset()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Part 3: Interactive EPA Control\n",
                "\n",
                "Read EPA from user input and use it to steer the response."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def conversational_turn(\n",
                "    user_input: str,\n",
                "    target_e: float = None,\n",
                "    target_p: float = None, \n",
                "    target_a: float = None,\n",
                "    match_user: bool = False,\n",
                "):\n",
                "    \"\"\"\n",
                "    Process a conversational turn.\n",
                "    \n",
                "    Args:\n",
                "        user_input: The user's message\n",
                "        target_e/p/a: Target EPA values for response (None = no steering)\n",
                "        match_user: If True, match the user's EPA values\n",
                "    \"\"\"\n",
                "    # Read user's EPA\n",
                "    user_epa = read_epa_scores(\n",
                "        rep_pipeline, rep_readers, user_input, reading_layers\n",
                "    )\n",
                "    print(f\"User EPA: E={user_epa['evaluation']:.2f}, P={user_epa['potency']:.2f}, A={user_epa['activity']:.2f}\")\n",
                "    \n",
                "    # Determine response EPA\n",
                "    if match_user:\n",
                "        e_coeff = user_epa['evaluation']\n",
                "        p_coeff = user_epa['potency']\n",
                "        a_coeff = user_epa['activity']\n",
                "    else:\n",
                "        e_coeff = target_e if target_e is not None else 0\n",
                "        p_coeff = target_p if target_p is not None else 0\n",
                "        a_coeff = target_a if target_a is not None else 0\n",
                "    \n",
                "    print(f\"Response steering: E={e_coeff:.2f}, P={p_coeff:.2f}, A={a_coeff:.2f}\")\n",
                "    \n",
                "    # Create prompt\n",
                "    system = \"You are a helpful assistant in a natural conversation.\"\n",
                "    prompt = format_llama3_prompt(system, user_input)\n",
                "    \n",
                "    # Create activations\n",
                "    activations = make_epa_activations(\n",
                "        rep_readers, control_layers,\n",
                "        e_coeff=e_coeff, p_coeff=p_coeff, a_coeff=a_coeff,\n",
                "        device=model.device, dtype=model.dtype\n",
                "    ) if any([e_coeff, p_coeff, a_coeff]) else None\n",
                "    \n",
                "    # Generate\n",
                "    output = control_pipeline(\n",
                "        prompt,\n",
                "        activations=activations,\n",
                "        max_new_tokens=100,\n",
                "        do_sample=True,\n",
                "        temperature=0.7,\n",
                "        pad_token_id=tokenizer.pad_token_id,\n",
                "    )\n",
                "    \n",
                "    response = output[0]['generated_text'][len(prompt):]\n",
                "    return response, user_epa"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Angry user, respond calmly\n",
                "print(\"=\" * 60)\n",
                "print(\"SCENARIO: Angry user, calm response\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "user_msg = \"This is absolutely unacceptable! I demand a refund right now!\"\n",
                "print(f\"\\nUser: {user_msg}\\n\")\n",
                "\n",
                "# Respond with low activity, high evaluation (calm and kind)\n",
                "response, user_epa = conversational_turn(\n",
                "    user_msg,\n",
                "    target_e=1.0,   # Kind\n",
                "    target_p=0.5,   # Slightly firm\n",
                "    target_a=-1.0,  # Calm\n",
                ")\n",
                "\n",
                "print(f\"\\nAssistant: {response}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Match user's energy\n",
                "print(\"=\" * 60)\n",
                "print(\"SCENARIO: Excited user, match energy\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "user_msg = \"Oh my gosh, this is amazing! I'm so excited about this project!\"\n",
                "print(f\"\\nUser: {user_msg}\\n\")\n",
                "\n",
                "response, user_epa = conversational_turn(\n",
                "    user_msg,\n",
                "    match_user=True,  # Match user's EPA\n",
                ")\n",
                "\n",
                "print(f\"\\nAssistant: {response}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## LoRRA Fine-tuning Reference\n",
                "\n",
                "For fine-tuning low-rank adapters to learn EPA control, see the `lorra_finetune/` directory.\n",
                "\n",
                "Key steps:\n",
                "1. Create training data with EPA-labeled responses\n",
                "2. Configure LoRRA with target layers\n",
                "3. Fine-tune with representation-aligned loss\n",
                "\n",
                "```python\n",
                "# Example config for LoRRA\n",
                "lorra_config = {\n",
                "    'target_layers': list(range(10, 25)),\n",
                "    'alpha': 16,\n",
                "    'beta': 0.5,\n",
                "    'direction': epa_directions,\n",
                "}\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "repeng",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
